{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc9656c",
   "metadata": {},
   "source": [
    "Put all the data cleaning and formatting steps into functions, and create a main function that performs all the cleaning and formatting.\n",
    "\n",
    "Write these functions in a separate .py file(s). By putting these steps into functions, we can make the code more modular and easier to maintain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a236096c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting clean_data.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile clean_data.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "# Data Cleaning and FormattingÂ¶\n",
    "# Cleaning Column Names\n",
    "\n",
    "#change column names to lower case\n",
    "from pandas import DataFrame\n",
    "\n",
    "# Define the changes and string operations for each column\n",
    "changes = {\n",
    "    'gender': {'female': 'F', 'Male': 'M', 'Femal': 'F', 'm': 'M'},\n",
    "    'state': {'AZ': 'Arizona', 'Cali': 'California', 'WA': 'Washington'},\n",
    "    'education': {'Bachelors': 'Bachelor'},\n",
    "    # Add more columns and their changes as needed\n",
    "}\n",
    "\n",
    "\n",
    "def change_col_names_to_lower_case(df: DataFrame) -> DataFrame:\n",
    "    '''\n",
    "    This function changes the case of the column names to lowercase.\n",
    "\n",
    "    Args:\n",
    "    - df (DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: A new DataFrame with lowercase column names.\n",
    "    '''\n",
    "    # Create a new DataFrame with lowercase column names\n",
    "    #df1 = df.copy()\n",
    "    df.columns = df.columns.str.lower()\n",
    "    \n",
    "    return df\n",
    "# replacing White spaces in column names by _\n",
    "\n",
    "def replace_white_spaces_in_col_names(df: DataFrame) -> DataFrame:\n",
    "    '''\n",
    "    This function white spaces in the column names.\n",
    "\n",
    "    Args:\n",
    "    - df (DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: A new DataFrame with remove white spaces from column names.\n",
    "    '''\n",
    "    # Create a new DataFrame with lowercase column names\n",
    "    df.columns = df.columns.str.replace(\" \",\"-\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "#other changes in data frame and st could be replaced for state\n",
    "\n",
    "def rename_col_names(df: DataFrame, column_names:dict)-> DataFrame:\n",
    "    \"\"\"\n",
    "    Rename columns in a DataFrame based on a dictionary of column names.\n",
    "\n",
    "    Args:\n",
    "    - df (DataFrame): The input DataFrame.\n",
    "    - column_names (dict): A dictionary mapping old column names to new column names.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: A new DataFrame with renamed columns.\n",
    "    \"\"\"\n",
    "    # Use the .rename() method with columns parameter\n",
    "    df=df.rename(columns=column_names)\n",
    "    return df\n",
    "# Function to clean columns by mapping values\n",
    "def clean_column_by_mapping(df):\n",
    "    \"\"\"\n",
    "    Clean columns in the DataFrame by mapping values to new values.\n",
    "\n",
    "    Args:\n",
    "    - df (DataFrame): The input DataFrame.\n",
    "    - changes (dict): A dictionary where keys are column names and values are dictionaries\n",
    "                      mapping old values to new values for each column.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The DataFrame with specified columns cleaned.\n",
    "    \"\"\"\n",
    "    for column, value_mapping in changes.items():\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].replace(value_mapping)\n",
    "    return df\n",
    "\n",
    "# Function to clean columns by applying a string operation\n",
    "def clean_column_by_string_operation(df, string_operations):\n",
    "    \"\"\"\n",
    "    Clean columns in the DataFrame by applying string operations to their values.\n",
    "\n",
    "    Args:\n",
    "    - df (DataFrame): The input DataFrame.\n",
    "    - changes (dict): A dictionary where keys are column names and values are functions\n",
    "                      to apply to the column values.\n",
    "    - string_operations (dict): A dictionary where keys are column names and values\n",
    "                                are string operations to apply to the column values.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The DataFrame with specified columns cleaned.\n",
    "    \"\"\"\n",
    "    for column, string_operation in string_operations.items():\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].apply(string_operation)\n",
    "    return df\n",
    "\n",
    "\n",
    "def strip_percentage(value):\n",
    "    return str(value).rstrip('%')\n",
    "\n",
    "def map_vehicle_class(value):\n",
    "    return 'Luxury' if value in ['Sports Car', 'Luxury SUV', 'Luxury Car'] else value \n",
    "def handle_missing_values(df: DataFrame, numerical_columns1_mean: list, numerical_columns2_median: list, categorical_columns_mode: list) -> DataFrame:\n",
    "    '''\n",
    "    Handle missing values in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "    - df (DataFrame): The input DataFrame with missing values.\n",
    "    - numerical_columns1_mean (list): List of numerical columns for which to fill missing values with mean.\n",
    "    - numerical_columns2_median (list): List of numerical columns for which to fill missing values with median.\n",
    "    - categorical_columns_mode (list): List of categorical columns for which to fill missing values.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The DataFrame with missing values handled.\n",
    "    '''\n",
    "    \n",
    "    # Identify columns with missing values\n",
    "    null_columns = df.columns[df.isnull().any()]\n",
    "\n",
    "    # Iterate through the columns with null values and print the count of null values in each\n",
    "    for column in null_columns:\n",
    "        null_count = df[column].isnull().sum()\n",
    "        print(f\"Column '{column}' has {null_count} null values.\")\n",
    "\n",
    "    # Fill missing values in the 'id' column with random UUIDs\n",
    "    df['id'].fillna(uuid.uuid4(), inplace=True)\n",
    "\n",
    "    # Convert columns to numeric and replace non-numeric values with NaN\n",
    "    #df[numerical_columns1_mean] = pd.to_numeric(df[numerical_columns1_mean], errors='coerce')\n",
    "    #df[numerical_columns2_median] = pd.to_numeric(df[numerical_columns2_median], errors='coerce')\n",
    "\n",
    "    # Fill missing values in numerical columns with their mean or median\n",
    "    for col in numerical_columns1_mean:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "    \n",
    "    for col in numerical_columns2_median:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    # Fill missing values in categorical columns with their mode\n",
    "    for col in categorical_columns_mode:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "    # Fill NaN values with zero for numerical columns in numerical_columns1_mean\n",
    "    df[numerical_columns1_mean] = df[numerical_columns1_mean].fillna(0)\n",
    "    \n",
    "\n",
    "    # Convert filled columns to integers using applymap\n",
    "    #for col in numerical_columns2_median:\n",
    "    df[numerical_columns1_mean] = df[numerical_columns1_mean].applymap(int)\n",
    "    df[numerical_columns2_median] = df[numerical_columns2_median].applymap(int)\n",
    "\n",
    "    # Iterate through the columns with null values again and print the count of null values in each\n",
    "    null_columns = df.columns[df.isnull().any()]\n",
    "    for column in null_columns:\n",
    "        null_count = df[column].isnull().sum()\n",
    "        print(f\"Column '{column}' has {null_count} null values.\")\n",
    "\n",
    "    return df\n",
    "# Identify duplicate rows\n",
    "def duplicate_rows(df:DataFrame,subset_columns:list)->DataFrame:\n",
    "    duplicates = df[df.duplicated()]\n",
    "\n",
    "# Print the duplicate rows\n",
    "    print(\"Duplicate Rows:\")\n",
    "    print(duplicates.count())\n",
    "\n",
    "\n",
    "# Remove duplicate rows based on the 'id' column\n",
    "    df_cleaned = df.drop_duplicates(subset=subset_columns)\n",
    "\n",
    "    duplicates = df_cleaned[df_cleaned.duplicated()]\n",
    "\n",
    "# Print the duplicate rows\n",
    "    print(\"Duplicate Rows:\")\n",
    "    print(duplicates.count())\n",
    "\n",
    "    df_cleaned.to_csv('cleaned_insurance_data.csv', index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d51ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e9dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
